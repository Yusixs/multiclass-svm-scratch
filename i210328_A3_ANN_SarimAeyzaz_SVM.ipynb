{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#ANN A3: Multi-class SVM Loss & Affine Layer backward pass\n",
        "# Submitted by: Sarim Aeyzaz (21i-0328)"
      ],
      "metadata": {
        "id": "GVEPiVEC4QHN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBL-SQwIN1_7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(X, Y, split = 0.25):\n",
        "\n",
        "  length = X.shape[0]\n",
        "  index_split = int(length * split)\n",
        "\n",
        "  # Generates random order of numbers from 0 till length\n",
        "  indices = np.random.permutation(length)\n",
        "  test_indices, train_indices = indices[:index_split], indices[index_split:]\n",
        "\n",
        "  X_train, X_test = X[train_indices], X[test_indices]\n",
        "  Y_train, Y_test = Y[train_indices], Y[test_indices]\n",
        "  return X_train, X_test, Y_train, Y_test"
      ],
      "metadata": {
        "id": "o1pMpra9ONWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(X, Y):\n",
        "  return (X == Y).sum() / len(Y) * 100"
      ],
      "metadata": {
        "id": "NmrRJ0wQOOY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "  def __init__(self):\n",
        "    self.thetas = None\n",
        "    self.lr = None\n",
        "\n",
        "  def __svm_loss_derrivative(self, X, y):\n",
        "    derr = X - X[np.arange(y.shape[0]), y].reshape(-1,1) # (135,5) - (135, 1) vectorized subtraction\n",
        "    derr[derr < 0] = 0 # Creating mask and replacing negative values with 0\n",
        "    loss = np.sum(derr) # Sum up the matrix to compute loss\n",
        "    derr[derr > 0] = 1 # Creating mask and replacing positive values with 1\n",
        "    derr[np.arange(y.shape[0]), y] = np.sum(derr, axis = 1) * -1 # Replace target label value with -1 * (sum of 1's in row)\n",
        "    return loss, derr\n",
        "\n",
        "  # Predict values given a feature vector\n",
        "  def __predict(self, X, theta):\n",
        "    answer = np.dot(X, theta) # (samples, features + 1) * (features + 1, labels)\n",
        "    return answer # (samples, labels)\n",
        "\n",
        "  # Update theta values based on partial derrivate error\n",
        "  def __gradient_descent(self, lr, theta, del_theta):\n",
        "    return theta - lr * del_theta.T\n",
        "\n",
        "  # Return weights (thetas) of the model\n",
        "  def Get_Weights(self):\n",
        "    return self.thetas\n",
        "\n",
        "  # Returns Logits of test data\n",
        "  def Predict_Confidence(self, X):\n",
        "    X = np.hstack((X, np.ones((X.shape[0], 1)))).T\n",
        "    predictions = np.dot(X.T, self.Get_Weights())\n",
        "    return predictions\n",
        "\n",
        "  # Predicts class of test data (argmax)\n",
        "  def Predict_Class(self, X):\n",
        "    X = self.Predict_Confidence(X)\n",
        "    return np.argmax(X, axis=1)\n",
        "\n",
        "  def Train(self, X, Y, alpha = 0.0001, loss_at_iter = 50, max_iter = None):\n",
        "\n",
        "    # Setting up some stuff\n",
        "    convergence_check = False\n",
        "    X = np.array(X) # Dimensions are: (samples, features)\n",
        "    X = np.hstack((X, np.ones((X.shape[0], 1)))) # Dimensions are (samples, features + 1)\n",
        "    Y = np.array(Y_train).reshape(-1,) # Dimensions are: (samples, )\n",
        "    Y_labels = np.unique(Y) # Number of unique elements of Y (labels)\n",
        "\n",
        "    self.thetas = np.empty((0,X.shape[1]), float)\n",
        "\n",
        "    # Handling Termination by changes in old and new loss values incase max_iter is not defined\n",
        "    if max_iter is None:\n",
        "      convergence_check = True\n",
        "      print(\"Convergence Criteria will be used\")\n",
        "\n",
        "    old_loss = 0\n",
        "    counter = 0\n",
        "\n",
        "    # Generating random weights\n",
        "    theta = np.random.random(size=(X.shape[1], len(Y_labels)))  # Dimensions of theta = (features + 1, labels)\n",
        "\n",
        "    while(True):\n",
        "\n",
        "      predictions = self.__predict(X, theta) # Returns (samples, labels)\n",
        "\n",
        "      loss, derrivative = self.__svm_loss_derrivative(predictions, Y) # Returns loss and derrivative\n",
        "\n",
        "      if (counter % loss_at_iter == 0):\n",
        "          print(f\"Loss at iteration {counter} = {loss}\")\n",
        "\n",
        "      if (loss == 0):\n",
        "        print(f\"Final Loss at iteration {counter} = {loss}\\n\")\n",
        "        self.thetas = theta\n",
        "        return\n",
        "\n",
        "      del_theta = np.dot(derrivative.T, X) / X.shape[0] # (labels, n) * (n, d) / number of x    For normalization\n",
        "\n",
        "      theta = self.__gradient_descent(alpha, theta, del_theta)\n",
        "\n",
        "      # Either do convergence check or max iteration check\n",
        "      if convergence_check:\n",
        "        if abs(old_loss - loss) / loss < 0.0001: # If the loss difference is lesser than 0.01%, break\n",
        "          print(\"Convergence Reached\")\n",
        "          break\n",
        "      else:\n",
        "        if (counter >= max_iter - 1): # If max iterations are reached, break\n",
        "          print(\"Maximum Iterations Reached\")\n",
        "          break\n",
        "\n",
        "      old_loss = loss\n",
        "      counter +=1\n",
        "\n",
        "    print(f\"Final Loss at iteration {counter} = {loss}\\n\")\n",
        "\n",
        "    self.thetas = theta\n"
      ],
      "metadata": {
        "id": "5kdf77PcOPo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y, Y_names = iris['data'], iris['target'], iris['target_names']\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, 0.1)\n",
        "\n",
        "nn = NeuralNetwork()\n",
        "nn.Train(X_train, Y, 0.01, 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRduD6aXRGAY",
        "outputId": "b433bfdb-b6c1-434e-a7e5-15f5761e1fb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convergence Criteria will be used\n",
            "Loss at iteration 0 = 804.7972130570148\n",
            "Loss at iteration 50 = 7.43677740604278\n",
            "Loss at iteration 100 = 7.858957662349513\n",
            "Loss at iteration 150 = 6.579129008541231\n",
            "Loss at iteration 200 = 4.94690451220563\n",
            "Loss at iteration 250 = 2.4297536810977354\n",
            "Loss at iteration 300 = 1.708940905574095\n",
            "Loss at iteration 350 = 1.1011040437454787\n",
            "Loss at iteration 400 = 0.8343384871768942\n",
            "Loss at iteration 450 = 0.7008093446888859\n",
            "Loss at iteration 500 = 0.6159477496882833\n",
            "Loss at iteration 550 = 0.6064573342267492\n",
            "Loss at iteration 600 = 0.5173410379304864\n",
            "Loss at iteration 650 = 0.5297228859581518\n",
            "Loss at iteration 700 = 0.5031735341555494\n",
            "Loss at iteration 750 = 0.49007862193787766\n",
            "Loss at iteration 800 = 0.3513881803754524\n",
            "Loss at iteration 850 = 0.47103723785911455\n",
            "Loss at iteration 900 = 0.30994077296805234\n",
            "Loss at iteration 950 = 0.29567364442994304\n",
            "Loss at iteration 1000 = 0.2785632730173093\n",
            "Loss at iteration 1050 = 0.26673364338767325\n",
            "Loss at iteration 1100 = 0.2545228111458657\n",
            "Loss at iteration 1150 = 0.2430980751486045\n",
            "Loss at iteration 1200 = 0.24730401375807887\n",
            "Loss at iteration 1250 = 0.2249647418152687\n",
            "Loss at iteration 1300 = 0.21689171671735874\n",
            "Loss at iteration 1350 = 0.20752844551896477\n",
            "Convergence Reached\n",
            "Final Loss at iteration 1362 = 0.20528920294236208\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(nn.Predict_Confidence(X_test))\n",
        "predicted = nn.Predict_Class(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfAfote4RGe7",
        "outputId": "a4be05dd-cde3-44e1-84a7-9e481c881087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5.09500027  4.71171634  3.59603323]\n",
            " [ 6.6633369   7.30124981  7.24047851]\n",
            " [ 6.87292302  6.99321968  6.7918506 ]\n",
            " [ 7.51539531  7.87618328  8.03282431]\n",
            " [ 9.38317389  9.61787044  9.87037219]\n",
            " [ 6.59126334  6.67747402  6.30621918]\n",
            " [ 7.72432538  8.22133873  8.37395865]\n",
            " [ 4.97117224  4.68173748  3.68139394]\n",
            " [ 8.14546209  8.59323821  8.84274104]\n",
            " [ 5.16328105  4.64636372  3.57144081]\n",
            " [ 8.11887641  8.74292315  8.94742301]\n",
            " [ 4.83152049  4.57437336  3.49900456]\n",
            " [ 9.67296412 10.04712752 10.43440203]\n",
            " [ 6.24252821  6.60275754  6.376815  ]\n",
            " [ 6.77847424  7.0642109   6.78242875]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Predicted: {predicted}\")\n",
        "print(f\"Actual: {Y_test}\")\n",
        "print(f\"Accuracy: {calculate_accuracy(predicted, Y_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ira9LGrlVt05",
        "outputId": "97151b56-397d-4f2f-b63e-1b6287e4cb6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: [0 1 1 2 2 1 2 0 2 0 2 0 2 1 1]\n",
            "Actual: [0 1 1 2 2 1 2 0 2 0 2 0 2 1 1]\n",
            "Accuracy: 100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_CRs0y-z136B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}